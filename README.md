# PrettyLlama

<img src="https://github.com/thenry42/PrettyLlama/blob/main/utils/PrettyLlama.png" alt="Project Logo" width="200" height="200">

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)

## Introduction

### Ollama x Glow

<img src="https://www.google.com/url?sa=i&url=https%3A%2F%2Fsedona.fr%2F2024%2F04%2F04%2Follama-executer-les-modeles-de-langages-llm-en-local%2F&psig=AOvVaw0oAkYr2a3ZXz88DqrNCvsv&ust=1718630787213000&source=images&cd=vfe&opi=89978449&ved=0CBEQjRxqFwoTCIiSqd6c4IYDFQAAAAAdAAAAABAZ" width="100" height="100"> <img src="https://camo.githubusercontent.com/e20892cc1a5b1775de4ba67dd0baad0fc62191da6b71efff35b71f89800c1da2/68747470733a2f2f73747566662e636861726d2e73682f676c6f772f676c6f772d62616e6e65722d6769746875622e676966" width="300" height="100">

PrettyLlama is a Simple CLI tool that allows to run ollama models and render their answers in Markdown.
It works bu using Ollama (obviously) and Glow.

## Installation

### Prerequisites

First, you need to install [Ollama](https://github.com/ollama/ollama).

Secondly, you need to install [Glow](https://github.com/charmbracelet/glow).

